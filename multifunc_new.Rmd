---
title: "A New Multifunc"
date: "`r format(Sys.time(), '%d %B, %Y')`" 
output: 
    html_document:
      keep_md: yes
---
```{r libraries, include=FALSE, message=FALSE, warning=FALSE}
#library(devtools)
#install_github("multifunc", "jebyrnes")

library(multifunc)
library(tidyverse)
library(broom)
library(ggplot2)
library(viridis)
library(gridExtra)
theme_set(theme_bw(base_size=17))

source("Functions.R")
```

#### Introduction

The past decade has witnessed the growth of the concept of ecosystem **multifunctionality**. Multifunctionality is defined as a measure of the simultaneous performance of multiple functions. Note that we do not say "ecosystem functions", as multifunctionality is a broader concept that can be easily applied outside of community and ecosystem ecology - and even outside of ecology altogether. This concept has proven unifying in a number of different situations. In the Biodiversity Ecosystem Function literature, it has enabled researchers to realize that, while specific species often drive single functions, different species often drive different functions enhancing diversity's importance as progressively more functions are considered (Duffy et al. 2003, Hector and Bagchi 2007, Lefcheck et al. 2015). Researchers are beginning to recognize that foundation species create multifunctional landscapes (Angelini et al. DATE) that differ not only in species diversity and abundance, but ecosystem-level properties. Invasion biology has begun to use multifunctionality to quantify whole-system level changes (Ramus et al. PNAS). Multifunctionality has tremendous use to applied ecology as well. Managers often attempt to work towards the provision of multiple ecosystem services (REFS) - fundamentally the same concept as multifunctionality - or have come to understand single ecosystem services as the sum of multiple different ecosystem functions (Nilsson et al. 2017). Across each of these areas, we see that the concept of multifunctionality as a potential linchpin linking community and ecosystem ecology. 

However, adoption of multifunctionality as a fundamental concept providing this linchpin has been slow. Nor is there a robust theoretical core behind multifunctionality, further hindering its penetration into scientific thinking. We posit that there is at least one simple explanation behind this lack of progress. While some researchers and managers have latched on to the concept of multifunctionality, the field still lacks a clear single metric that it can use to summarize the phenomenon. Frankly, current metrics range from the simple yet misstated to the complex and accurate yet unweildy. We acknowledge some of our own blame in this state of affairs (Byrnes et al. 2014); although we do note that throwing even some of the finest minds against this problem in a stimulating working group format over multiple years (we are thankful for NCEAS for providing this venue) has likely resulted in more ink impregnated on foreheads hitting whiteboards than should be typical. We are similarly thankful that many in the field have continued to be critical and force us to look at our current failures with honesty (Fabian's paper).

Here we briefly review the current state of affairs, propose a solution, and discuss some of the ongoing challenges to the field, including whole conceptual fields of exploration that we feel have been entirely missed.

#### The current state of multifunctional affairs

The definition of multifunctionality presents a challenge. How to we define a metric that captures both the level of performance of a broad suite of functions as well as the distribution of differences in performance between functions? Researchers have sought to capture this question in four ways, after standardizing functions to similar levels in order to prevent apples-to-oranges comparisons.

First, on the side of simplicty, taking the average of all functions ([REFS]). This approach appears on its face appealing, particularly as it provides a metric that can be put on a y-axis while a predictor is on the x. However, it sacrifices crucial information about the system. An arithmetic mean tells us, were we to sample any one function, what level of functioning would we expect? Consider two plots - one where all functions are similar and performing at half their value and one where half of the functions are at their maximum while half are absent. The averaging approach says that they are identical. Geometric averaging appears to get around this problem to some degree, as a geometric mean is approximately the arithmetic mean minus the variance of observations. However, given its formulation, one critically low function can bias the measurement, nor do we always have a sufficient sample of functions to achieve that approximation.

Second, we have metrics of the Multivariate Diversity Interactions framework (Dooley et al. 2015). This elegant framework allows us to tease apart the importance of correlations between functions and the contribution of different drivers to simultaneous change in those functions. It does not, however, provide a holistic metric of multifunctionality *per se*, much like the overlap approach before it (Hector and Bagchi 2007) which is really a generalization of SÃ¸renson overlap to provides key information on redundancy versus unique contributions of species. While we gain rich information about a system, we do not gain holistic interpretability.

Last, we have the multiple threshold approach. This approach seeks to balance the goals of measuring the simultaneous performance of multiple ecosystem functions with the arbitrariness of choosing a threshold of relevance for those functions. We note that many who use it simply choose a single threshold, although present many in their appendicies (e.g., SOMEONE). This is a reasonable choice in order to understand a single set of observations. Further, for those who do look at all thresholds, the results are, frankly, difficult to interpret as the quantities they yeild are non-obvious in their links to the concept of multifunctionality. The approach yields rich information about multifunctionality *sensu stricto*, but in so doing, becomes unweildy for most if not all who choose to use it. Related, more recent efforts have sought to use dimensionality-reducing techniques which has yielded metrics that while useful lack interpretable meaning (Weigelt et al. 2017)

How can we solve this? What is a good metric of multifunctionality that yields the information we need in a proper holistic fashion such that we might even ultimately link it back to theory?

#### A Way Forward

The definition of multifunctionality presents a challenge. How do we define a metric that captures both the level of performance of a broad suite of functions as well as the distribution of differences in performance between functions? The issue of total level of performance is easily linked to thinking about total community size. In our case, a simple averaging across functions should suffice and addresses the level of performance across the whole community of functions. This leaves open the question of how this average is distributed across functions.  
  
This problem of assessing the distribution of differences across functions seems akin to the problem of capturing diversity of species within a community. We know the "richness" of functions - it is the total number of functions we are observing. This richness can be partitioned independently into evenness and a measure of compositional complexity (Jost 2010). In the diversity literature, this metric of complexity can be simply translated into an effective number of species, i.e., the number of equally abundant species that would produce the same metric (Jost 2006, 2010), via Hill Numbers. This concept of effective number of functions is equally powerful in the context of measuring multifunctionality. For some set of functions that have been standardized to a common scale (i.e., between 0 and 1) such that $F_{1,2,3...S}$ is their level of function

$$
\tag{eq. 1}
p_i = \frac{F_i}{\sum F_i}
$$

$$
\tag{eq. 2}
^{q}N = \left(\sum_{i=1}^{S}p_{i}^q\right)^{1/(1-q)}
$$

where $N_q$ is the effective number of functions for some order q. Adapting from Jost (2006), if q = 0, this is the total number of functions, S. If q<1, then functions at low level dominate the calculation. For q = 1, the approximation of this function is equivalent to results from Shannon diversity for species, $^{1}N = exp(-\sum{p_i\;log \;p_i})$. For q>1, higher functions are given greater weight. At q = 2, we get results that are equivalent to the number of functions calculated from Simpson's diversity. If one of our goals is to up-weight high performing functions, q=2 is a reasonable choice. However, to be conservative, q=1 is sufficient.

At this point, we can calculate evenness as this effective number of functions divided by the number of functions divided we are observing (Jost 2010). 

$$
\tag{eq. 3}
^{q}E = \frac{^{q}N}{S}
$$

Armed with functional evenness, effective number of functions, and average level of function, discussed previously and here defined as $A$, we can turn to creating a meaningful multifunctionality metric based on evenness. 

$$
\tag{eq. 4}
M_e = E\, A
$$

This metric can also be rescaled back to units of number of functions by multiplying it by total number of functions providing an metric on the scale of the absolute number of functions, such that $M_f = M_e S$.

Why must we consider level of function and evenness together in one metric?  From a convenience standpoint, a combined metric satisfies our definition of multfunctionality. More importantly, both metrics are non-independent, with the upper limit of $^{q}E = 1$ and the lower limit is set by a combination of the produce of AS and $\lfloor AS \rfloor$ (see [Appendix 1](#Appendix1) and [Appendix 2](#Appendix2) for the derivations). 




```{r show_conceptual_new, echo=FALSE, cache=TRUE, fig.cap = "Relationship between Evenness of functions and average level of functions for 4 functions at q = 1,2,3, and 4."}

shannon_s <- function(...){
  f <- c(...)
  p <- f/sum(f)
  p <- p[p>0]
  exp(-sum(p*log(p)))
}

gmean <- function(x, p=1) (length(x)^-1 * sum(x^p)) ^ (1/p)

f <- function(...){
  x <- c(...)
  as <- length(x)*mean(x)
  x <- x[x>0]
#  exp(-1*sum(x/as*log(x/as)))
#  exp(-1/as*sum(x*log(x/as)))
 # exp(-1/as*sum(x*log(x)-x*log(as)))
#  exp(-1/as*sum(x*log(x))+ 1/as*sum(x*log(as)))
  #exp(-1/as*sum(x*log(x))+ log(as)/as*sum(x))
  ##exp(-1/as*sum(x*log(x))) * exp( log(as)/as*sum(x))
  ##exp(-1/as*sum(x*log(x))) * as^(sum(x)/as)
  g <- floor(as)
#  ret <- exp(-1/as*(g*log(1/as)+(as-g)*log((as-g)/as)))
#  if(is.nan(ret)) ret <- exp(-1/as*(g*log(1/as)))
#  ret
  #exp(g*log(as)/as + log(as)/as*(as-g) - (as-g)/as*log(as-g))
  #simplified from http://www.wolframalpha.com/input/?i=simplify+exp(g*log(x)%2Fx+%2B+log(x)%2Fx*(x-g)+-+1%2Fx*(x-g)*log(x-g))
  ret <- -1*as*(as-g)^(g/as)/(g-as) #
  if(is.nan(ret)) ret <- as^(g/as) #exp(g*log(as)/as)
  ret
}

get_mfn_floor <- function(a, s, q){
  if(q==1){
    as <- a*s
    g <- floor(as)
    ret <- -1*as*(as-g)^(g/as)/(g-as)
    ix <- is.nan(ret)
    ret[ix] <- as[ix]^(g[ix]/as[ix])#exp(-1/as[ix]*(g[ix]*log(1/as[ix])))
    return(ret)
  }
  (a^-q*s^-q*(floor(a*s) + (a*s-floor(a*s))^q))^(1/(1-q))
}


eq_lower <- crossing(data.frame(a = seq(0,1,0.01)), data.frame(q = 1:4)) %>%
  group_by(q, a) %>%
  mutate(e_upper=1, e_lower=get_mfn_floor(a, 4, q)/4)

ggplot(eq_lower, aes(x=a, y=e_lower, 
                          ymin = e_lower,
                          ymax = e_upper,
                          fill = fct_rev(factor(q)),
                          color= fct_rev(factor(q)))) +
  geom_ribbon(alpha=0.7) +
  xlab("Average Level of Functioning") +
  ylab("Evenness of Functioning") +
  ylim(c(0,1)) +
  xlim(c(0,1))+
  scale_fill_brewer(palette="Accent") +
  scale_color_brewer(palette="Accent") +
  guides(color="none", fill=guide_legend("Order (q)")) 
  
```

```{r test_limits, eval=FALSE}
library(multifunc)
z <- crossing(a=seq(0,1,.1), b = seq(0,1,.1), c = seq(0,1,.1), d = seq(0,1,.1))
z$e <- even_fact(z)
z$avg <- (z$a + z$b + z$c + z$d)/4
z$m <- z$e * z$avg
plot(e ~ avg, data=z)
min(z$e)
```

```{r show_conceptual, eval=FALSE, echo=FALSE, cache=TRUE, fig.width=10}

fun_df <- make_data(n = 4, length.out=10) %>%
  mutate(mf_a = rowMeans(.),
         mf_even = even_fact(.))


sim_plot <- ggplot(fun_df) +
  theme_bw(base_size=14) +
  aes(x=mf_a, y=mf_even, color=mf_a*mf_even) +
  geom_point() +
  geom_hline(yintercept=0.5, col="red", lty=2)+
  geom_vline(xintercept=0.5, col="red", lty=2) +
  scale_color_viridis(begin=0.3, option="B",
                     guide=guide_colorbar("Multifunctionality")) +
  xlab("Average Level of Functioning") +
  ylab("Evenness of Functioning") +
  ylim(c(0,1)) +
  xlim(c(0,1))
  

concep_df <- crossing(mf_a=seq(0,1,length.out=400), 
                      mf_e=seq(0,1,length.out=400)) %>%
  filter(mf_e>=mf_a) %>%
  filter(mf_e >=1/10)%>%
  mutate(mf = mf_e * mf_a)

concep_plot <- ggplot(concep_df, aes(x=mf_a, y=mf_e, fill=mf)) +
  geom_raster(interpolate=TRUE) +
  scale_fill_viridis(begin=0.3, option="B",
                     guide=guide_colorbar("Multifunctionality"))+
  scale_x_continuous(breaks = c(0, 1/10, 0.5, 1),
                     labels = c(0, "1/S", 0.5, 1),
                     lim=c(0,1), minor_breaks = NULL) +
  scale_y_continuous(breaks = c(0, 1/10, 0.5, 1),
                     labels = c(0, "1/S", 0.5, 1),
                     lim=c(0,1), minor_breaks = NULL) +
  geom_hline(yintercept=0.5, col="black", lty=2)+
  geom_vline(xintercept=0.5, col="black", lty=2) +
  theme_bw() +
  xlab("Average Level of Functioning") +
  ylab("Evenness of Functioning")

grid.arrange(sim_plot, concep_plot, ncol=2)
```

Further, having this single metric now allows us to begin to examine it as any other response variable. In the BEF world, we might look at additive partioning in addition to complementary overlap approaches. In global change biology, we can look at stability, resistance, and resilience. The options are open.

#### Application to real data

To see how this metric can be used, consider the example of Duffy et al. 2003. In this experiment, Duffy and colleagues sought to examine how biodiversity of grazers influences multiple different ecosystem functions in seagrass ecosystems. Using the functions discussed in the paper, we standardized and reflected them as per how Duffy et al. discuss their results. Comparing  M<sub>e</sub>, average functional performance, and functional evenness (Figure 2).

```{r duffy, echo=FALSE}
data("duffy_2003")

duffyAllVars <- qw(grazer_mass,wkall_chla,tot_algae_mass,
                  Zost_final_mass,sessile_invert_mass,sediment_C)

duffyAllVars.std <- paste0(duffyAllVars, ".std")
#re-normalize so that everything is on the same 
#sign-scale (e.g. the maximum level of a function is the "best" function)
#and the dataset is cleaner
duffy <- duffy_2003 %>%
 dplyr::select(treatment, diversity, one_of(duffyAllVars)) %>%
 dplyr::mutate(wkall_chla = -1*wkall_chla + max(wkall_chla, na.rm=T),
               tot_algae_mass = -1*tot_algae_mass + max(tot_algae_mass, na.rm=T)) 

#first, mean multifunctionality
duffy <- duffy %>%
 cbind(getStdAndMeanFunctions(duffy, duffyAllVars)) %>%
 dplyr::rename(`Average Function` = meanFunction, Richness=diversity)

#now evenness
duffy[["Functional Evenness"]] <- duffy %>% funcEven(duffyAllVars.std)

#Now our multifunctionality metric - I could have
#done this as a product, but I'm guessing people will want a function
duffy$Multifunctionality <- duffy %>% getMF(duffyAllVars)

duffy_for_plotting <- duffy %>%
 select(Richness, treatment, 
        `Average Function`, `Functional Evenness`, Multifunctionality) %>%
 gather(index, value, -Richness, -treatment)

ggplot(duffy_for_plotting,
      aes(x=Richness, y=value)) +
 facet_wrap(~index) +
 geom_point() +
 theme_bw(base_size=17) +
 stat_smooth(method="lm", color="black") +
  ylab("Value")
```

```{r duffy_analysis}
duffy_coefs <- duffy_for_plotting %>%
  group_by(index) %>%
  nest() %>%
  mutate(mod = map(data, ~lm(value ~ Richness, data=.))) %>%
  mutate(coefs = map(mod, ~tidy(.))) %>%
  unnest(coefs) %>%
  ungroup() %>%
  filter(term == "Richness") %>%
  mutate(estimate = round(estimate, 4),
         std.error = round(std.error, 4)) %>%
  select(-statistic, -p.value)

knitr::kable(duffy_coefs)
```

What is intriguing about this is that across the experiment, functional evenness remained high. Thus, the slope of the multifunctionality relationship remains tied to the average (Figure 3, Table 1). Further, we can see the positive correlation between the two variables given their functional constraint (Figure 3). 

```{r duffy_trdeoff, echo=FALSE}
ggplot(duffy,
       aes(`Average Function`, `Functional Evenness`, color=factor(Richness))) +
  geom_point() +
  theme_bw() +
  ylim(c(0,1)) +
  xlim(c(0,1))
```

Regardless, our results broadly reproduce the qualitative conclusions of Duffy et al. (2003) but with additional clarity, as they do for biodepth as well (SUPPLEMENT).
[*so, do we want to include biodepth in the supplement or in the main text - it makes the paper seem beefier if we analyse both data sets in text - however, we can decide later*]

#### Robutness of metric
# FABIAN DO MAGIC HERE

#### A note on correlated functions

A great deal of the confusion in the multifunctionality literature even when using metrics has sprung from the issue of correlation between functions (BACK AND FORTH IN PNAS). In no small part this is likely due to the incessant focus on accounting for correlation in areas such as spatial and temporal analysis. To have correlations between functions seems to somehow either "contaminate" results and make them suspect or, for others, only correlated functions are valid to indicate multifunctionality (PNAS ref). Neither of these are strictly true. 

The difficulty comes down to defining just what a "function" is. This semantic argument has led down the path of considering "true" functions as the single response to a driver that gives rise to all other responses. Consider the example of aboveground and belowground production in plants. The two are driven by similar, if not mutually overlapping, biological processes. Thus, are they truly separate functions? If biological reductionism in functional space is the goal of a researcher, then dimensional reduction techniques before analysis would seem to be in order. We offer a caution, however, that techniques such as PCA reduce dimensions with no basis in biology. While they are useful  in terms of compressing information and addressing the problem in creating a multifunctionality metric that can be used (REF), there is no inherent meaning in their outputs. Moreover, the formulae are dependent on the data used to create the PCA, and thus difficult to generalize across studies. Rather, Confirmatory Factor Analysis (ref) with a meaningful underlying factor structure might provide a far more useful and biologically meaningful option. Further, it can be tested for measurement invariance, and as such can be shown to be generalizable across studies with the same functions measured.

In contrast, when we consider an ecosystem function as a measurement of some flux within an ecosystem, the issue of correlation becomes moot. Was there a flux, or was there not a flux? Was that flux uniquely relevant to some other ecosystem processes? Similarly, managers have goals that focus on functions and services that are independent of any biological reductionism. Hence, sweeping this correlation under the rug for a single metric of multifunction is not only acceptable, but desirable in terms of defining a clear metric of the concept. 

That said, this point of view treats correlation between functions as if they are static. Indeed, if a driver increases multifunctionality, then it is pushing multiple functions to higher levels at the same time. It's not only plausible but possible that in highly multifunctional systems, functions are more highly correlated when function is low. If researchers are interested in exploring the correlation structure of functions - or even how that structure changes across treatments (something to our knowledge that has not been done) - then that is a separate piece of a good ecological story. To our knowledge, this has not been robustly explored, nor is there a solid body of theory addressing this phenomen of multifunctional correlation. Perhaps it is time to explore it further. Regardless, even changing correlation across levels of a driver does not invalidate any metric of multifunctionality seeking to capture simultaneous change in multiple functions. It comes down to a researchers question and how that question forces them to define functions. This is an epistomological point beyond the scope of any metric.

#### Thinking Beyond Measured Functions

One potential pitfall of this technique is to assume that it is robust to a researchers choice in what functions to measure in terms of the inferences it can deliver about a system. In an ideal world, when we quantify multifunctionality we would think of all possible functions as a population. We would then measure a random (or stratified!) sample of functions in order to draw good inferences about how a driver influences system-wide multifunctionality. To our knowledge, this type of careful thought about relevant functions from a population sampling perspective has never been applied in multifunctionality research. We hope we are wrong about this, and applaud anyone who has done so. Recently, several excellent guides to standardized measuring of relevant ecosystem functions have begun to appear in the literature (TWO TREE PAPERS). We suggest these as a starting point for any researchers interested in thinking carefully about the topic, in addition to fruitful discussions of with ecosystem ecologists working in the same system. They are highly likely to disabuse any community ecologist of the notion that they have fully captures a good sample of the population of relevant functions, and provide guidance on further ways to do so (J. Bowen, pers. com.).

#### Conclusions

We hope that this piece will provide the field of multifunctionality with a way out of its current state of division and confusion. Further, we hope it provides food for additional theory that addresses the causes and consequences of ecosystem multifunctionality, something that is currently sorely lacking. We have been heartened by the idea leaving the cradle of the field of biodiversity and ecosystem function, and feel that it has the promise to provide a holistic unifying concept for anyone interested in capturing a snapshot of system dynamics in single meaningful metric.


#### Appendix 1: Upper Limit of Multifunctional Evenness is 1 {#Appendix1}
While eqn. 3 will always have a maximum upper bound of 1 at any level of averge level of functioning (i.e., all functions are performing at the same level), $^{q}E$ has a lower bound set by $A$. We can see this mathematically. We start by noting that

$$
\tag{eq. 5}
p_i = \frac{F_i}{\sum_{i=1}^S{F_i}}
$$

Substituting this in for values of $p_i$ in eqn. 2, then pulling out constants we get 

$$
\tag{eq. 6}
^{q}N = \left[{\frac{1}{A^q \cdot S^{q}}} \cdot \sum_{i=1}^{S}F_{i}^q \right]^{1/(1-q)}
$$

Given that the generalized mean for order q, which we'll call $^{q}A$ such that $^{1}A = A$ is defined as
$$
A_{q} = \left[ \frac{1}{S}\sum_{i=1}^{S}F_{i}^q\right]^{1/q} 
$$

Leading to 

$$
\sum_{i=1}^{S}F_{i}^q = A_{q}^qS
$$

Then we can substitute this into the equation 6, now denoting the arithmetic mean as $A_1$ such that

$$
\begin{aligned} 
^{q}N &= \left[A_{q}^q \cdot A_1^{-q} \cdot S^{1-q} \right]^{1/(1-q)} \\
&\Rightarrow S\left[A_{q}^q \cdot A_1^{-q} \right]^{1/(1-q)}
\end{aligned} 
$$

Assuming that $q \le 1$, the generalized mean inequality states thatfor q $\ge$ 1, $A_1 \le \ A_q$. When all functions perform leading to the same level,  $A_1 = \ A_q$, leading to $^{q}N = S$ and thus $^{q}E = 1$

#### Appendix 2: Lower Limit of Multifunctional Evenness {#Appendix2}
As the lower portion of the curve occurs at minimum evenness (i.e., maximum dominance), it is constrained at a lower bound given that we know the average of all functions. For example, for a set of functions where $0 < A  \le 1/S$, all functions save one are 0 and for the remaining function, $0 < F_S \le 1$. If $1/S < A \le 2/S$, then $F_{S-1} = 1$, $0 < F_{S-1} \le 1$, and $F_1...F_{S-2} = 0$. Thus, for any number of functions, S, and any average level of functions, A, where $0 \le F_i \le 1$, if we define $g = \lfloor AS \rfloor$

**NOTE TO SELF, CHECK SUBSCRIPTS**
$$
\begin{aligned} 
&F_{1}...F_{S-g-1} = 0 \\
&F_{S-g} = AS - \lfloor AS \rfloor \\
&F_{S-g+1}...F_{S} = 1
\end{aligned} 
$$

Plugging this into equation 6, we get

$$
\tag{eq. 7}
^{q}N_{lower} = \left[{A^{-q} \cdot S^{-q}} (\lfloor AS \rfloor + F_{S-g}\;^q) \right]^{1/(1-q)}
$$

For q=1, we can begin by re-arranging the limit using a substition from equation 5.

$$
\begin{aligned}
&^{1}N_{lower} = exp\left(-\sum p_i \;log\; p_i\right) \\
&\Rightarrow exp\left(-\sum \frac{F_i}{AS} \;log\; \frac{F_i}{AS}\right)\\
&\Rightarrow exp\left(-\frac{1}{AS}  \sum (F_i \; log \; F_i \; - F_i\; log \; AS)\right) \\
\end{aligned}
$$

We can use the same approach as before, taking 0 log 0 = 0, to get a lower limit for q=1 as

$$
\begin{aligned}
&^{1}N_{lower} = exp\left(\lfloor AS \rfloor\frac{log AS}{AS} + \frac{log AS}{AS}(AS-\lfloor AS \rfloor) - \frac{(AS-\lfloor AS \rfloor)}{AS}(AS-\lfloor AS \rfloor) \right) \\
&\Rightarrow \frac{-AS(AS-\lfloor AS \rfloor)^\frac{(AS-\lfloor AS \rfloor)}{AS}}{(\lfloor AS \rfloor - AS)}
\end{aligned}
$$

When $AS-\lfloor AS \rfloor = 0$, this reduces to $AS ^ {\frac{\lfloor AS \rfloor}{AS}}$.